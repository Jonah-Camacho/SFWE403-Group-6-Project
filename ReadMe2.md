ğŸ¾ ChatCat Assistant
<div align="center">
University of Arizona Software Engineering Chatbot
A full-stack AI chatbot providing information about the University of Arizona's Software Engineering programs
Show Image
Show Image
Show Image
Show Image
</div>

ğŸ“‹ Table of Contents

Features
Architecture
Prerequisites
Installation

1. Install Required Programs
2. Backend Setup
3. Frontend Setup


Running the Application
Project Structure
Troubleshooting
Deployment
Credits


âœ¨ Features

ğŸ§  AI-Powered Responses using Ollama's local LLM
ğŸ’¬ Real-time Chat Interface built with React
ğŸ” Semantic Search with embedding-based retrieval
âš¡ Fast API Backend with Python FastAPI
ğŸ¨ Modern UI powered by Vite
ğŸ”’ Privacy-First - all processing happens locally


ğŸ—ï¸ Architecture
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  React Frontend â”‚ â†’ http://localhost:5173
â”‚   (Vite Dev)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ proxy
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FastAPI Backend â”‚ â†’ http://127.0.0.1:8000
â”‚   (Python 3.x)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Ollama API    â”‚ â†’ http://localhost:11434
â”‚  (Local Models) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“¦ Prerequisites
Before you begin, ensure you have the following installed:
ToolVersionDownload LinkPython3.10+python.orgNode.js18+ (LTS)nodejs.orgOllamaLatestollama.com

ğŸ’¡ Windows Users: Run all commands in Command Prompt (cmd) with Administrator privileges when possible.


ğŸš€ Installation
1. Install Required Programs
ğŸ Python
Check if Python is installed:
cmdpython --version
âœ… During installation, make sure to check "Add Python to PATH"
ğŸ“¦ Node.js & npm
Check if Node.js is installed:
cmdnode -v
npm -v
ğŸ§  Ollama
After installing Ollama, verify it's running:
cmdollama --version
Pull the required models:
cmdollama pull nomic-embed-text
ollama pull gemma3:1b

2. Backend Setup (FastAPI + Ollama)
Navigate to Project Root
cmdcd F:\SFWE403-Group-6-Project

ğŸ“ Adjust the path to match your project location

Create Virtual Environment
cmdpython -m venv .venv
Activate Virtual Environment
cmd.venv\Scripts\activate
You should see (.venv) prefix in your terminal
Install Dependencies
cmdpip install -r requirements.txt
This installs:

fastapi - Web framework
uvicorn - ASGI server
pydantic - Data validation
numpy - Numerical operations
tiktoken - Token counting
ollama - LLM interface


3. Frontend Setup (React + Vite)
Open New Terminal

âš ï¸ Keep the backend terminal running

Navigate to Frontend Directory
cmdcd F:\SFWE403-Group-6-Project\ChatCat-Assistant
Install Dependencies
cmdnpm install
This installs:

React & React DOM
Vite build tool
Babel compiler
UI dependencies


â–¶ï¸ Running the Application
Terminal 1: Start Backend
cmdcd F:\SFWE403-Group-6-Project
.venv\Scripts\activate
python main.py
âœ… Backend running at: http://127.0.0.1:8000
Terminal 2: Start Frontend
cmdcd F:\SFWE403-Group-6-Project\ChatCat-Assistant
npm run dev
```
âœ… Frontend running at: `http://localhost:5173`

### ğŸ‰ Access the Application
Open your browser and navigate to: **http://localhost:5173**

---

## ğŸ“‚ Project Structure
```
SFWE403-Group-6-Project/
â”‚
â”œâ”€â”€ ğŸ“„ main.py                    # FastAPI backend server
â”œâ”€â”€ ğŸ“„ requirements.txt           # Python dependencies
â”œâ”€â”€ ğŸ“„ README.md                  # This file
â”œâ”€â”€ ğŸ“„ ChatBot.md                 # Knowledge base
â”œâ”€â”€ ğŸ“ .venv/                     # Python virtual environment
â”‚
â””â”€â”€ ğŸ“ ChatCat-Assistant/         # React frontend
    â”œâ”€â”€ ğŸ“„ package.json           # Node dependencies
    â”œâ”€â”€ ğŸ“„ vite.config.js         # Vite configuration
    â”œâ”€â”€ ğŸ“ src/
    â”‚   â”œâ”€â”€ ğŸ“„ App.jsx            # Main React component
    â”‚   â”œâ”€â”€ ğŸ“„ App.css            # Styles
    â”‚   â””â”€â”€ ğŸ“ assets/            # Static assets
    â””â”€â”€ ğŸ“ node_modules/          # Installed packages

ğŸš‘ Troubleshooting
<details>
<summary><b>ModuleNotFoundError</b></summary>
Ensure virtual environment is activated and dependencies are installed:
cmd.venv\Scripts\activate
pip install -r requirements.txt
</details>
<details>
<summary><b>Ollama not found</b></summary>

Verify Ollama is installed: ollama --version
Ensure Ollama service is running in the background
Try restarting Ollama from the system tray

</details>
<details>
<summary><b>vite: command not found</b></summary>
Reinstall frontend dependencies:
cmdcd ChatCat-Assistant
npm install
</details>
<details>
<summary><b>CORS or API not connecting</b></summary>

Verify backend is running on port 8000
Check vite.config.js proxy target matches backend URL
Ensure no firewall is blocking local connections

</details>
<details>
<summary><b>Port already in use</b></summary>

Close other running servers
Change port in main.py (backend) or vite.config.js (frontend)
Kill process using the port: netstat -ano | findstr :8000

</details>

ğŸ§¾ Quick Reference
TaskCommandActivate Python environment.venv\Scripts\activateInstall backend dependenciespip install -r requirements.txtRun backendpython main.pyNavigate to frontendcd ChatCat-AssistantInstall frontend dependenciesnpm installRun frontendnpm run devView applicationOpen http://localhost:5173

ğŸŒ Deployment
<details>
<summary><b>Backend Deployment Options</b></summary>
Deploy to cloud platforms:

Render
Railway
Fly.io

Required environment variables:
envEMBED_MODEL=nomic-embed-text
LLM=gemma3:1b
</details>
<details>
<summary><b>Frontend Deployment Options</b></summary>
Deploy to static hosting:

Netlify
Vercel

Build command:
cmdnpm run build
Deploy the generated dist/ folder
</details>

ğŸ‘¥ Credits
<div align="center">
SFWE403 Group 6 â€“ ChatCat Assistant
University of Arizona
Built with â¤ï¸ using FastAPI â€¢ Ollama â€¢ React â€¢ Vite

Technologies Used
Show Image
Show Image
Show Image
Show Image
Show Image
Show Image
</div>

<div align="center">
â¬† Back to Top
</div>